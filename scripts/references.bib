@article{lakhani2017,
author = {Paras Lakhani and Baskaran Sundaram},
title = {Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks},
journal = {Radiology},
volume = {284},
number = {2},
pages = {574-582},
year = {2017},
doi = {10.1148/radiol.2017162326},
    note ={PMID: 28436741},

URL = { 
        https://doi.org/10.1148/radiol.2017162326
    
},
eprint = { 
        https://doi.org/10.1148/radiol.2017162326
    
}
,
    abstract = {PurposeTo evaluate the efficacy of deep convolutional neural networks (DCNNs) for detecting tuberculosis (TB) on chest radiographs.Materials and MethodsFour deidentified HIPAA-compliant datasets were used in this study that were exempted from review by the institutional review board, which consisted of 1007 posteroanterior chest radiographs. The datasets were split into training (68.0\%), validation (17.1\%), and test (14.9\%). Two different DCNNs, AlexNet and GoogLeNet, were used to classify the images as having manifestations of pulmonary TB or as healthy. Both untrained and pretrained networks on ImageNet were used, and augmentation with multiple preprocessing techniques. Ensembles were performed on the best-performing algorithms. For cases where the classifiers were in disagreement, an independent board-certified cardiothoracic radiologist blindly interpreted the images to evaluate a potential radiologist-augmented workflow. Receiver operating characteristic curves and areas under the curve (AUCs) were used to assess model performance by using the DeLong method for statistical comparison of receiver operating characteristic curves.ResultsThe best-performing classifier had an AUC of 0.99, which was an ensemble of the AlexNet and GoogLeNet DCNNs. The AUCs of the pretrained models were greater than that of the untrained models (P < .001). Augmenting the dataset further increased accuracy (P values for AlexNet and GoogLeNet were .03 and .02, respectively). The DCNNs had disagreement in 13 of the 150 test cases, which were blindly reviewed by a cardiothoracic radiologist, who correctly interpreted all 13 cases (100\%). This radiologist-augmented approach resulted in a sensitivity of 97.3\% and specificity 100\%.ConclusionDeep learning with DCNNs can accurately classify TB at chest radiography with an AUC of 0.99. A radiologist-augmented approach for cases where there was disagreement among the classifiers further improved accuracy.Â© RSNA, 2017 }
}

@Inbook{Le2011,
author="Le, Kim",
editor="Meghanathan, Natarajan
and Kaushik, Brajesh Kumar
and Nagamalai, Dhinaharan",
title="Chest X-Ray Analysis for Computer-Aided Diagnostic",
bookTitle="Advanced Computing: First International Conference on Computer Science and Information Technology, CCSIT 2011, Bangalore, India, January 2-4, 2011. Proceedings, Part III",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="300--309",
abstract="X-ray is a classical method for diagnosis of some chest diseases. The diseases are curable if they are detected in their early stages. Detection of chest diseases is mostly based on chest X-ray images (CXR). This is a time consuming process. In some cases, medical experts had overlooked the diseases in their first examinations on CXR, and when the images were re-examined, the disease signs could be detected. Furthermore, the number of CXR to examine is numerous and far beyond the capability of available medical staff, especially in developing countries.",
isbn="978-3-642-17881-8",
doi="10.1007/978-3-642-17881-8_29",
url="https://doi.org/10.1007/978-3-642-17881-8_29"
}
